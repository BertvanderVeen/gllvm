#' @title Generalized Linear Latent Variable Models
#' @description Fits a generalized linear latent variable model for multivariate data, with quadratic latent variables. The model is fitted with variational
#' approximations.
#'
#' @param y (n x m) matrix of responses.
#' @param X matrix or data.frame of environmental covariates.
#' @param TR matrix or data.frame of trait covariates.
#' @param data data in long format, that is, matrix of responses, environmental and trait covariates and row index named as ?\200\231id?\200\231. When used, model needs to be defined using formula. This is alternative data input for y, X and TR.
#' @param formula an object of class 'formula' (or one that can be coerced to that class): a symbolic description of the model to be fitted.
#' @param num.lv  number of latent variables, d, in gllvm model. Non-negative integer, less than number of response variables (m). Defaults to 2.
#' @param family  distribution function for responses. Options are \code{poisson(link = 'log')}, \code{'negative.binomial'} (with log link), \code{binomial(link = 'probit')} and \code{'ordinal'}.
#' @param row.eff  \code{FALSE}, \code{TRUE} or \code{'random'}, Indicating whether row effects are included in the model as a fixed or as a random effects. Defaults to \code{FALSE} when row effects are not included.
#' @param starting.val starting values can be generated by fitting model without latent variables, and applying factorial analysis to residuals to get starting values for latent variables and their coefficients (\code{starting.val = 'res'}). Another options are to use zeros as a starting values (\code{starting.val = 'zero'}) or initialize starting values for latent variables with (n x num.lv) matrix. Defaults to \code{'res'}, which is recommended.
#' @param start.method ordination method to retrieve starting values. The default is Factor analysis (FA), with alternative Correspondence Analysis (CA).
#' @param start.fit object of class 'gllvm' or 'gllvm.quadratic' which can be given as starting parameters. When an object of class 'gllvm' is provided, starting values for quadratic coefficients are generated with chosen 'starting.val'.
#' @param sd.errors  logical. If \code{TRUE} (default) standard errors for parameter estimates are calculated.
#' @param n.init number of initial runs. Uses multiple runs and picks up the one giving highest log-likelihood value. Defaults to 1.
#' @param offset vector or matrix of offset terms.
#' @param Lambda.struc  covariance structure of VA distributions for latent variables,'unstructured' or 'diagonal'.
#' @param diag.iter  if larger than 1, the updating of variational (covariance) parameters is sped-up by first fitting a model with a diagonal structure.
#' @param trace logical, if \code{TRUE} in each iteration step of n.init information on current step will be printed. Defaults to FALSE. 
#' @param trace2 local, if \code{TRUE} prints the optimizer trace.
#' @param Lambda.start starting values for variances in VA distributions for latent variables in variational approximation method. Defaults to 0.1.
#' @param reltol  convergence criteria for log-likelihood, defaults to 1e-6.
#' @param maxit maximum number of iterations within \code{optim} function, defaults to 1000.
#' @param seed a single seed value, defaults to \code{NULL}.
#' @param optimizer The log-likelihood can be optimized using \code{'\link{optim}'} (default) or \code{'\link{nlminb}'} (only with diag.iter=0).
#' @param jitter.var jitter variance for starting values of latent variables. Defaults to 0, meaning no jittering.
#' @param ridge \code{TRUE} fits a ridge penalty to shrink the latent variable (linear and quadratic effects)
#' @param ridge.quadratic \code{TRUE} fits a ridge penalty to shrink the quadratic effect of the latent variable
#' @param par.scale (see \code{'\link{optim}'} for details) Here, either "coef" to scale all parameters to equal magnitudes, or a single value to scale all parameters with, e.g. 0.0001)
#' @param fn.scale (see \code{'\link{optim}'} for details)
#' @param grad.check defaults to TRUE. Checks if TMB provided gradient is near zero, i.e. if the model has converged.
#' @param zeta.struc Structure for cut-offs in the ordinal model. Either "common", for the same cut-offs for all species, or "species" for species-specific cut-offs. For the latter, classes are arbitrary per species, each category per species needs to have at least one observations. Defaults to "species".
#' 
#' @details
#' Fits the species packing model by generalized linear latent variable models with quadratic latent variables.
#' Method can be used with two types of latent variable models depending on covariates. If only
#' site related environmental covariates are used, the expectation of response \eqn{Y_{ij}} is determined by
#'
#' \deqn{g(\mu_{ij}) = \eta_{ij} = \alpha_i + \beta_{0j} + x_i'\beta_j + u_i'\theta_j + u_i'\D_{j}u_i,}
#'
#' where \eqn{g(.)} is a known link function, \eqn{u_i} are \eqn{d}-variate latent variables (\eqn{d}<<\eqn{m}), \eqn{\alpha_i} is an optional row effect
#' at site \eqn{i}, and it can be fixed or random effect, \eqn{\beta_{0j}} is an intercept term for species \eqn{j}, \eqn{\beta_j}, \eqn{\theta_j} and \eqn{D_j}  are column
#' specific coefficients related to covariates and the latent variables, respectively.
#'
#' An alternative model is the fourth corner model (Brown et al., 2014, Warton et al., 2015) which will be fitted if also trait covariates
#' are included. The expectation of response \eqn{Y_{ij}} is
#'
#' \deqn{g(\mu_{ij}) = \alpha_i + \beta_{0j} + x_i'\beta_x + TR_j'\beta_t + vec(B)*kronecker(TR_j,X_i) + u_i'\theta_j + u_i'\D_{j}u_i}
#'
#' where g(.), \eqn{u_i}, \eqn{\beta_{0j}} and \eqn{\theta_j} are defined as above. Vectors \eqn{\beta_x} and \eqn{\beta_t} are the main effects
#' or coefficients related to environmental and trait covariates, respectively, matrix \eqn{B} includes interaction terms.
#' The interaction/fourth corner terms are optional as well as are the main effects of trait covariates.
#'
#'
#' The method is sensitive for the choices of initial values of the latent variables. Therefore it is
#' recommendable to use multiple runs and pick up the one giving the highest log-likelihood value.
#' However, sometimes this is computationally too demanding, and default option
#' \code{starting.val = 'res'} is recommended. For more details on different starting value methods, see Niku et al., (2018).
#'
#' Models are implemented using TMB (Kristensen et al., 2015) applied to variational approximation (Hui et al., 2017).
#'
#' With ordinal family response classes must start from 0 or 1.
#'
#' \subsection{Distributions}{
#'
#'   Mean and variance for distributions are defined as follows.
#'\itemize{
#'   \item{For count data \code{family = poisson()}:} {Expectation \eqn{E[Y_{ij}] = \mu_{ij}}, variance \eqn{V(\mu_{ij}) = \mu_{ij}}, or}
#'   \item{ \code{family = 'negative.binomial'}:}{ Expectation \eqn{E[Y_{ij}] = \mu_{ij}}, variance \eqn{V(\mu_{ij}) = \mu_{ij}+\frac{\mu_{ij}}{\phi_j}}}
#'
#'   \item{For binary data \code{family = binomial()}:}{ Expectation \eqn{E[Y_{ij}] = \mu_{ij}}, variance \eqn{V(\mu_{ij}) = \mu_{ij}(1-\mu_{ij})}.}
#'
#'   \item{For ordinal data \code{family = 'ordinal'}:}{ Cumulative probit model, see Hui et.al. (2016).}
#' }
#' }
#'
#'@note If function gives warning: 'In f(x, order = 0) : value out of range in 'lgamma'', optimizer have visited an area where gradients become too big. It is automatically fixed by trying another step in the optimization process, and can be ignored if errors do not occur.
#'
#' @return An object of class 'gllvm' includes the following components:
#'
#'
#'  \item{call }{function call}
#'  \item{logL }{log likelihood}
#'  \item{lvs }{latent variables}
#'  \item{params}{list of parameters
#'  \itemize{
#'    \item{theta }{ coefficients related to latent variables}
#'    \item{beta0 }{ column specific intercepts}
#'    \item{Xcoef }{ coefficients related to environmental covariates X}
#'    \item{B }{ coefficients in fourth corner model}
#'    \item{row.params }{ row-specific intercepts}
#'    \item{phi }{ dispersion parameters \eqn{\phi} for negative binomial or standard deviation for gaussian family}
#'    \item{inv.phi }{ dispersion parameters \eqn{1/\phi} for negative binomial}
#'    }}
#'  \item{sd }{ list of standard errors of parameters}
#'  \item{prediction.errors }{ list of prediction covariances for latent variables and variances for random row effects when method \code{'LA'} is used}
#'  \item{A, Ar }{ covariance matrices for variational densities of latent variables and variances for random row effects}
#'
#' @author Jenni Niku <jenni.m.e.niku@@jyu.fi>, Wesley Brooks, Riki Herliansyah, Francis K.C. Hui, Sara Taskinen, David I. Warton
#' @references
#' Brown, A. M., Warton, D. I., Andrew, N. R., Binns, M., Cassis, G., and Gibb, H. (2014). The fourth-corner solution - using predictive models to understand how species traits interact with the environment. Methods in Ecology and Evolution, 5:344-352.
#'
#' Dunn, P. K. and Smyth, G. K. (2005).  Series evaluation of tweedie exponential dispersion model densities. Statistics and Computing, 15:267-280.
#'
#' Hui, F. K. C., Taskinen, S., Pledger, S., Foster, S. D., and Warton, D. I. (2015).  Model-based approaches to unconstrained ordination. Methods in Ecology and Evolution, 6:399-411.
#'
#' Hui, F. K. C., Warton, D., Ormerod, J., Haapaniemi, V., and Taskinen, S. (2017).  Variational approximations for generalized linear latent variable models. Journal of Computational and Graphical Statistics. Journal of Computational and Graphical Statistics, 26:35-43.
#'
#' Kasper Kristensen, Anders Nielsen, Casper W. Berg, Hans Skaug, Bradley M. Bell (2016). TMB: Automatic Differentiation and Laplace Approximation. Journal of Statistical Software, 70(5), 1-21.
#'
#' Niku, J., Warton,  D. I., Hui, F. K. C., and Taskinen, S. (2017). Generalized linear latent variable models for multivariate count and biomass data in ecology. Journal of Agricultural, Biological, and Environmental Statistics, 22:498-522
#'
#' Niku, J., Brooks, W., Herliansyah, R., Hui, F. K. C., Taskinen, S., and Warton,  D. I. (2018). Efficient estimation of generalized linear latent variable models. Submitted.
#'
#' Warton, D. I., Guillaume Blanchet, F., O'Hara, R. B., Ovaskainen, O., Taskinen, S., Walker, S. C. and Hui, F. K. C. (2015). So many variables: Joint modeling in community ecology. Trends in Ecology & Evolution, 30:766-779.
#'
#'@seealso  \code{\link{coefplot.gllvm.quadratic}}, \code{\link{confint.gllvm.quadratic}}, \code{\link{ordiplot.gllvm.quadratic}}, \code{\link{plot.gllvm.quadratic}}, \code{\link{residuals.gllvm}}, \code{\link{summary.gllvm.quadratic}}.
#' @examples
#'## Load a dataset from the mvabund package
#'data(antTraits)
#'y <- as.matrix(antTraits$abund)
#'X <- as.matrix(antTraits$env)
#'TR <- antTraits$traits
#'# Fit model with environmental covariates Bare.ground and Shrub.cover
#'fit <- gllvm(y, X, formula = ~ Bare.ground + Shrub.cover,
#'             family = poisson())
#'ordiplot(fit)
#'coefplot(fit)
#'
#' \donttest{
#'## Example 1: Fit model with two latent variables
#'# Using variational approximation:
#'fitv0 <- gllvm(y, family = 'negative.binomial', method = 'VA')
#'ordiplot(fitv0)
#'plot(fitv0, mfrow = c(2,2))
#'summary(fitv0)
#'confint(fitv0)
#'
#'## Example 2: gllvm with environmental variables
#'# Fit model with two latent variables and all environmental covariates,
#'fitvX <- gllvm(formula = y ~ X, family = 'negative.binomial')
#'ordiplot(fitvX, biplot = TRUE)
#'coefplot(fitvX)
#'# Fit model with environmental covariates Bare.ground and Shrub.cover
#'fitvX2 <- gllvm(y, X, formula = ~ Bare.ground + Shrub.cover,
#'  family = 'negative.binomial')
#'ordiplot(fitvX2)
#'coefplot(fitvX2)
#'# Use 5 initial runs and pick the best one
#'fitvX_5 <- gllvm(y, X, formula = ~ Bare.ground + Shrub.cover,
#'  family = 'negative.binomial', n.init = 5, jitter.var = 0.1)
#'ordiplot(fitvX_5)
#'coefplot(fitvX_5)
#'
#'## Example 3: Data in long format
#'# Reshape data to long format:
#'datalong <- reshape(data.frame(cbind(y,X)), direction = 'long',
#'                    varying = colnames(y), v.names = 'y')
#'head(datalong)
#'fitvLong <- gllvm(data = datalong, formula = y ~ Bare.ground + Shrub.cover,
#'                family = 'negative.binomial')
#'
#'## Example 4: Fourth corner model
#'# Fit fourth corner model with two latent variables
#'fitF1 <- gllvm(y = y, X = X, TR = TR, family = 'negative.binomial')
#'coefplot(fitF1)
#'# Fourth corner can be plotted also with next lines
#'#fourth = fitF1$fourth.corner
#'#library(lattice)
#'#a = max( abs(fourth) )
#'#colort = colorRampPalette(c('blue','white','red'))
#'#plot.4th = levelplot(t(as.matrix(fourth)), xlab = 'Environmental Variables',
#'#              ylab = 'Species traits', col.regions = colort(100),
#'#              at = seq( -a, a, length = 100), scales = list( x = list(rot = 45)))
#'#print(plot.4th)
#'
#'# Specify model using formula
#'fitF2 <- gllvm(y = y, X = X, TR = TR,
#'  formula = ~ Bare.ground + Canopy.cover * (Pilosity + Webers.length),
#'  family = 'negative.binomial')
#'ordiplot(fitF2)
#'coefplot(fitF2)
#'
#'## Example 5: Random row effects
#'fitRand <- gllvm(y, family = 'negative.binomial', row.eff = 'random')
#'ordiplot(fitRand, biplot = TRUE)
#'}
#' @export
#'
#'@useDynLib gllvm2, .registration = TRUE
#'@importFrom vegan scores
#'@importFrom vegan tolerance
#'@importFrom vegan CCA
#'@importFrom TMB MakeADFun
#'@importFrom mvabund manyglm
#'@importFrom graphics abline axis par plot segments text points boxplot panel.smooth lines polygon
#'@importFrom grDevices rainbow
#'@importFrom stats AIC binomial dbinom dnorm factanal glm model.extract model.frame model.matrix model.response nlminb optim optimHess pbinom pnbinom pnorm ppois qnorm reshape residuals rnorm runif terms BIC qqline qqnorm sd pchisq formula ppoints quantile qchisq
#'@importFrom Matrix bdiag chol2inv diag
#'@importFrom MASS ginv polr
#'@importFrom mgcv gam predict.gam
#'@importFrom mvtnorm rmvnorm

gllvm.quadratic <- function(y = NULL, X = NULL, TR = NULL, data = NULL, formula = NULL, num.lv = 2, family, row.eff = FALSE, offset = NULL, 
    sd.errors = TRUE, Lambda.struc = "unstructured", diag.iter = 1, trace = FALSE, trace2 = FALSE, n.init = 1, reltol = 1e-08, seed = NULL, maxit = 1000, 
    start.fit = NULL, starting.val = "res", optimizer = "optim", Lambda.start = c(0.1, 0.5), jitter.var = 0, ridge = FALSE, 
    ridge.quadratic = FALSE, start.method="FA",par.scale=1, fn.scale=1, grad.check = TRUE, zeta.struc="species") {
    #build in gradient check
    randomX <- NULL
    term <- NULL
    datayx <- NULL
    
    if (!is.null(y)) {
        y <- as.matrix(y)
        if (is.null(X) && is.null(TR)) {
            datayx <- list(y)
            m1 <- model.frame(y ~ NULL, data = datayx)
            term <- terms(m1)
        } else if (is.null(TR)) {
            if (is.null(formula)) {
                ff <- formula(paste("~", "0", paste("+", colnames(X), collapse = "")))
                if (is.data.frame(X)) {
                  datayx <- list(y = y, X = model.matrix(ff, X))
                } else {
                  datayx <- list(y = y, X = X)
                }
                m1 <- model.frame(y ~ X, data = datayx)
                term <- terms(m1)
            } else {
                datayx <- data.frame(y, X)
                m1 <- model.frame(formula, data = datayx)
            }
            term <- terms(m1)
        } else {
            term <- NULL
        }
        p <- NCOL(y)
        n <- NROW(y)
        if (p == 1) 
            y <- as.matrix(y)
    } else {
        if (!is.null(data)) {
            if (is.null(formula)) 
                stop("Define formula when 'data' attribute is used.")
            if ("id" %in% colnames(data)) {
                id <- data[, "id"]
                n <- max(id)
                p <- dim(data)[1]/n
            } else {
                n <- NROW(data)
                p <- 1
                id <- 1:n
            }
        }
        
        cl <- match.call()
        mf <- match.call(expand.dots = FALSE)
        m <- match(c("formula", "data", "na.action"), names(mf), 0)
        mf <- mf[c(1, m)]
        mf$drop.unused.levels <- TRUE
        mf[[1]] <- as.name("model.frame")
        mf <- eval(mf, parent.frame())
        term <- attr(mf, "terms")
        abundances <- model.response(mf, "numeric")
        if (any(is.na(abundances))) 
            stop("There are NA values in the response.")
        y <- abundances
        # 
        X <- model.matrix(term, mf)
        
        atr <- c(attr(X, "assign"))
        if (sum(atr) > 0) {
            X <- X[, (atr > 0) * 1:ncol(X)]
        } else {
            X <- NULL
        }
        
        if (NCOL(y) == 1 && !is.null(data)) {
            y <- matrix(y, n, p)
            colnames(y) <- paste("y", 1:p, sep = "")
        }
        try(if (is.null(X)) {
            datayx <- data.frame(y = y)
        } else {
            datayx <- data.frame(y = y, X = X)
        }, silent = TRUE)
        
        if (!is.null(data)) {
            frame1 <- mf
            X <- TR <- NULL
            if (length(attr(term, "term.labels")) > 0) {
                datax <- frame1[, colnames(frame1) != "y"]
                colnames(datax) <- colnames(frame1)[colnames(frame1) != "y"]
                # datax <- frame1[, attr(term, 'term.labels')[attr(term, 'order') == 1]] colnames(datax) <- attr(term, 'term.labels')[attr(term,
                # 'order') == 1]
                
                for (k in 1:ncol(datax)) {
                  lngth <- NULL
                  namek <- colnames(datax)[k]
                  for (i in 1:n) {
                    lngth <- c(lngth, length(unique(datax[(id == i), k])))
                  }
                  if (max(lngth) == 1) {
                    if (!is.null(X)) 
                      X <- data.frame(X, datax[1:n, k]) else X <- data.frame(datax[1:n, k])
                    
                    colnames(X)[ncol(X)] <- namek
                  } else {
                    if (!is.null(TR)) {
                      TR <- data.frame(TR, datax[id == 1, k])
                    } else {
                      TR <- data.frame(datax[id == 1, k])
                    }
                    colnames(TR)[ncol(TR)] <- namek
                  }
                }
            }
        }
    }
    p <- NCOL(y)
    n <- NROW(y)
    if (p == 1) 
        y <- as.matrix(y)
    
    if (class(family) == "family") {
        family <- family$family
    }
    
    if (any(colSums(y) == 0)) 
        stop("There are responses full of zeros, model can not be fitted. \n")
    
    if (row.eff %in% c("fixed", "random", TRUE)) {
        if (p < 2) 
            stop("There must be at least two responses in order to include row effects. \n")
        if (any(rowSums(y) == 0)) 
            stop("There are rows full of zeros in y, model can not be fitted. \n")
    }
    
    if (p < 3 && !is.null(TR)) {
        stop("Fourth corner model can not be fitted with less than three response variables.\n")
    }

    
    if (!is.null(start.fit)) {
        if (class(start.fit) != "gllvm.quadratic"&class(start.fit) != "gllvm") 
            stop("Only object of class 'gllvm.quadratic' or 'gllvm' can be given as a starting parameters.")
          
        # 
        # if (!(family %in% c("poisson", "negative.binomial"))) 
        #     stop("Starting parameters can be given only for count data.")
        
    }
    # if(num.lv>=p){ stop('Number of latent variables (',num.lv,') must be less than number of response variables (',p,').');}
    
    
    if (is.null(offset)) 
        O <- matrix(0, nrow = n, ncol = p) else if (NCOL(offset) == 1) 
        O <- matrix(rep(offset), nrow = n, ncol = p) else O <- as.matrix(offset)
    
    start.lvs = NULL
    if (is.matrix(starting.val)) {
        start.lvs <- starting.val
        starting.val <- "random"
        if (ncol(start.lvs) != num.lv || nrow(start.lvs) != n) 
            stop("Given starting value matrix for latent variables has a wrong dimension.")
    }
    n.i <- 1
    
    out <- list(y = y, X = X, TR = TR, data = datayx, num.lv = num.lv, family = family, row.eff = row.eff, n.init = n.init, sd = FALSE, 
        Lambda.struc = Lambda.struc, TMB = TRUE, terms = term)
    
    if (family == "binomial") {
        out$link <- "probit"
    }
    out$offset <- offset
    if (row.eff == TRUE) 
        row.eff <- "fixed"
        if (!is.null(TR)) {
            fitg <- gllvm.TMB.trait.quadratic(y, X = X, TR = TR, formula = formula, num.lv = num.lv, family = family, Lambda.struc = Lambda.struc, 
                row.eff = row.eff, reltol = reltol, seed = seed, maxit = maxit, start.lvs = start.lvs, offset = O, sd.errors = sd.errors, 
                n.init = n.init, start.params = start.fit, optimizer = optimizer, starting.val = starting.val, randomX = randomX, 
                diag.iter = diag.iter, trace = trace, trace2 = trac2, Lambda.start = Lambda.start, jitter.var = jitter.var, ridge = ridge, ridge.quadratic = ridge.quadratic, start.method=start.method, par.scale=par.scale, fn.scale=fn.scale, zeta.struc = zeta.struc)
            out$X <- fitg$X
            out$TR <- fitg$TR
            
        } else {
            fitg <- gllvm.TMB.quadratic(y, X = X, formula = formula, num.lv = num.lv, family = family, Lambda.struc = Lambda.struc, 
                                        row.eff = row.eff, reltol = reltol, seed = seed, maxit = maxit, start.lvs = start.lvs, offset = O, sd.errors = sd.errors, 
                                        n.init = n.init, start.params = start.fit, optimizer = optimizer, starting.val = starting.val, 
                                        diag.iter = diag.iter, trace = trace, trace2 = trace2, Lambda.start = Lambda.start, jitter.var = jitter.var, ridge = ridge, ridge.quadratic = ridge.quadratic, start.method=start.method, par.scale=par.scale, fn.scale=fn.scale, zeta.struc = zeta.struc)
        }

    out$X.design <- fitg$X.design
    out$TMBfn = fitg$TMBfn
    out$logL <- fitg$logL
    out$method <- "VA"
    if (num.lv > 0) 
        out$lvs <- fitg$lvs
    out$X <- fitg$X
    
    out$params <- fitg$params
    if(family == "ordinal"){
      out$zeta.struc = zeta.struc
    }
    if (sd.errors) {
        out$sd <- fitg$sd
    }
    out$A <- fitg$A
    out$Ar <- fitg$Ar
    
    if (!is.null(randomX)) {
        out$corr <- fitg$corr
        out$Xrandom <- fitg$Xrandom
    }
    out$start <- fitg$start
    
    
    if (family == "negative.binomial") 
        out$params$inv.phi <- 1/out$params$phi
    if (is.infinite(out$logL)) {
        warning("Algorithm converged to infinity, try other starting values or different method.")
        cat("Algorithm converged to infinity, try other starting values or different method. \n")
    }
    out$formula <- fitg$formula
    if (is.null(out$terms)) 
        out$terms <- fitg$terms
    if (is.finite(out$logL) && !is.null(TR) && NCOL(out$TR) > 0 && NCOL(out$X) > 0) {
        out$fourth.corner <- try(getFourthCorner(out), silent = TRUE)
    }
    if (is.finite(out$logL) && row.eff == "random") {
        if (abs(out$params$sigma) < 0.02 && max(abs(out$params$sigma - sqrt(out$Ar))) < 0.001) 
        cat("Random row effects ended up almost zero. Might be a false convergence or local maxima. You can try a simpler model, less latent variables or change the optimizer.")
    }
    if(grad.check==T&any(out$TMBfn$gr(out$TMBfn$par)>0.001)){
      cat( paste("Large gradient value(s) detected ", "(max was ",round(max(out$TMBfn$gr(out$TMBfn$par)),3), "). Model might not have converged. \n",sep=""))
    }
  
    out$convergence <- fitg$convergence
    out$call <- match.call()
    class(out) <- "gllvm.quadratic"
    return(out)
}
